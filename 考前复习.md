# 第一章 操作系统引论

## 操作系统介绍

### 定义：是一种软件

**操作系统是**一组用于控制和管理计算机系统硬件和软件资源、合理地对各类作业进行调度，以及方便用户使用的**程序集合**。

### 地位：软件管理硬件和软件

操作系统是裸机之上的第一层**软件**，是建立其他所有软件的基础。它是整个系统的控制管理中心，**既管硬件，又管软件**，它为其它软件提供运行环境。

### **基本特征：并发、共享、异步、虚拟**

- 并发：是指两个或多个活动在同一给定的时间间隔中进行。注意**并行**：两个或多个活动在在**同一时刻**发生
- 共享：是指计算机系统中的资源被**多个进程所共用**。
- 异步：进程以**不可预知**的速度向前推进
- 虚拟：把一个物理上的实体变为若干个**逻辑上的对应物**。
- **最基本特征：并发、共享（两者互为存在条件）**

### 主要功能：处理机管理、存储器管理、[文件管理](https://so.csdn.net/so/search?q=文件管理&spm=1001.2101.3001.7020)、设备管理

- 处理机管理：主要功能包括**进程控制、进程同步、进程通信、死锁处理、处理器调度**等
- 存储器管理：主要包括**内存分配、地址映射、内存保护与共享和内存扩充**等功能
- 文件管理：包括**文件存储空间管理、目录管理及文件读写管理和保护等**
- 设备管理：主要包括**缓存管理、设备分配、设备处理和虚拟设备**等功能

### 发展：辨析各个阶段的优缺点

### **手工操作阶段（此阶段无操作系统）**

缺点：人机速度矛盾

### **批处理阶段（操作系统开始出现）**

### 1.单道批处理阶段：一个CPU运行一个程序

优点：缓解人机速度矛盾

缺点：**系统资源利用率依然低**

### 2.多道批处理阶段（操作系统正式诞生）：一个CPU运行多个程序

优点：多道程序并发进行，**资源利用率高**

缺点：**不提供人机交互能力**（缺少交互性）

### **分时操作系统（不可以插队，有了人机交互）**

优点：**提供人机交互**

缺点：不能优先处理紧急事物

### **实时操作系统（可以插队）**

1.硬实时系统：必须在被控制对象规定时间内完成（火箭发射）

2.软实时系统：可以松一些（订票）

优点：可以优先处理紧急事物

从可靠性看实时操作系统更强，从交互性看分时操作系统更强

## 不得不知的概念

### 两种指令：特权指令、非特权指令

**特权指令：不允许用户程序使用**（只允许操作系统使用）如IO指令、置中断指令

**非特权指令：普通的运算指令**

### 两种程序：**内核程序、应用程序**

**内核程序**：系统的管理者，可执行一切指令、运行在核心态

**应用程序**：普通用户程序只能执行非特权指令，运行在用户态

### 处理机状态

用户态（目态）：CPU只能执行非特权指令

核心态（管态、内核态）：可以执行所有指令

用户态到核心态：通过中断（是硬件完成的）

核心态到用户态：特权指令psw的标志位：0用户态  1核心态

常考谁在用户态执行，谁在核心态执行

### 原语

1.处于操作系统的最底层，是最接近硬件的部分

2.这些程序的运行具有原子性，其操作只能一气呵成

3.这些程序的运行时间都较短，而且调用频繁

### 中断和异常

内中断（异常，信号来自内部）

- 自愿中断---指令中断
- 强迫中断：硬件中断、软件中断

外中断（中断，信号来自外部）

- 外设请求
- 人工干预

### 系统调用

系统给程序员（应用程序）提供的唯一接口，可获得OS的服务，在用户态发生，在核心态处理

### 体系结构

大内核

微内核



# 第二，三章 进程，处理机调度和死锁

## 进程管理

### 引入进程的目的

为了更好地描述和控制程序并发执行，实现操作系统的并发性和共享性（**进程是动态的，程序是静态的**）

### 定义

是计算机中的程序**关于某数据集合上的一次运行活动**，**是系统进行****资源分配和调度的基本单位**

> **在引入线程的操作系统中**，**线程是调度和分配**的基本**单位** ，**进程是资源**拥有的基本**单位**
>
> 在未引入线程的操作系统中，**进程是****系统进行****资源分配和调度的基本单位**

### 组成

PCB：保存进程运行期间相关数据，是**进程存在的\**唯一标志，\**\**常驻内存\****

程序段：能被进程调度到的CPU代码

数据段

### 进程的状态

状态种类

- 运行态：进程正在占用CPU
- 就绪态：进程已处于准备运行的状态，即进程获得了除处理机外地一切所需资源，一旦得到处理机即可运行
- 阻塞态：进程由于等待某一事件不能享用CPU
- 创建状态：进程正在被创建
- 结束状态：进程正在从系统消失

状态变化

就绪态->运行态：处于就绪态的进程被调度后，获得处理机资源（分派处理机时间片）

运行态->就绪态：系时间片用完或在可剥夺统中有更高级的进程进入

运行态->阻塞态：进程需要的某一资源还没有准备好

阻塞态->就绪态：进程等待的时间到来时

进程状态转化图：

![img](D:\Typora\Images\f6019219d00d4b72b8c3eb68fc4c2547.png)

### 线程

引入目的：为了更好的使用多道程序并发执行，提高资源利用率和系统吞吐量

特点：是**程序执行的最小单位**，基本**不拥有任何系统资源**（**调度的基本单位**）

## 处理器调度

### 概念：多个进程选一个给处理机

是对处理机进行分配，即从就绪队列中按照定的算法（公平、高效）选择一个进程并将处理机分配给他运行，以实现进程并发进行

### 分类

- 高级调度（作业调度）（次数少）将作业从外存调入内存，创建进程，分配资源，并放入就绪队列。主要用于多道批处理系统中，分时和实时一般不用
- 中级调度（内存对换）（次数中）提高内存利用率和系统吞吐量。把暂时不能运行的进程调至外存等待(挂起状态)；把具备条件的又调入内存，放入就绪队列
- 低级调度（进程调度）（次数多）根据算法，决定就绪队列哪个进程能获得处理机，并分配。在多道批处理，分时和实时都必须配置。

### 调度方式

- 剥夺式：进程1正在运行，进程2权限高，所以进程2挤掉进程1位置
- 非剥夺式：进程1运行到底，或者因为自身原因(I/O请求，Block())不能继续运行，不会被其他进程抢占CPU；适用于大部分批处理系统，不适用于分时和实时系统

### 调度准则

- CPU利用率
- 系统吞吐量：单位时间内CPU完成的作业数
- 周转时间：作业完成时间-作业提交时间
- **带权周转时间W=T/Ts   其中T为周转时间，Ts为服务时间**
- 等待时间：进程等待处理的时间，有可能时间片用完了就继续等待
- 响应时间：提交到第一次运行的时间

### 算法

- 先来先服务 FCFS : first come first service
- 短作业优先 SJF ：哪个作业短，哪个先
- 优先级调度算法 PSA:外部赋予优先级
- **高响应比优先调度算法 HRRN：高响应比=（运行时间+等待时间）/运行时间**(计算结果越大优先级越高!!!)

> ![img](D:\Typora\Images\cae2f41be08a4760a4102279fd1eecfe.png)

- **时间片轮转：剥夺** 时间片的大小q很重要

  如果q很大，能使得每个进程都能在q时间片之内运行完，那么就退化为FCFS算法；其他情况需要画甘特图分析!!!

> | 作业 | 提交时间 | 运行时间 | 开始时间 | 结束时间 | 周转时间 | 带权周转时间 |
> | ---- | -------- | -------- | -------- | -------- | -------- | ------------ |
> | 1    | 1：00    | 4        | 1:00     | 11:00    | 10       | 2.5          |
> | 2    | 2：00    | 2        | 2:00     | 7:00     | 5        | 2.5          |
> | 3    | 2：00    | 6        | 3:00     | 14:00    | 12       | 2            |
> | 4    | 3：00    | 1        | 4:00     | 5:00     | 2        | 2 555        |
>
> ![img](D:\Typora\Images\b00041f9c007439bb8f2e470481298db.png)

- **多级反馈队列调度算法**

> 算法思想：对其他调度算法的折中权衡
>
> 算法规则
>
> 1．设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
> 2．新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下一级队列队尾。如果此时已经是在最下级的队列，则重新放回该队列队尾
> 3．只有第k级队列为空时，才会为k+1级队头的进程分配时间片
>
> 用于进程调度：用于作业/进程调度
> 是否可抢占?：抢占式的算法。在 k级队列的进程运行过程中，若更上级的队列(1~k-1级）中进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，**原来运行的进程放回k级队列队尾**。(因为没运行完，所以放到k级队尾就绪等待)
> 
>
> 
>  优缺点：
>
> 对各类型进程相对公平（FCFS的优点）﹔每个新到达的进程都可以
> 
>很快就得到响应（RR的优点)﹔
> 
>短进程只用较少的时间就可完成(SPF的优点）﹔
> 
>不必实现估计进程的运行时间（避免用户作假);
> 
>可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、I/o密集型进程
> 
>（拓展:可以将因I/o而阻塞的进程重新放回原队列，这样I/o型进程就可以保持较高优先级）
> 
>
> 是否会导致饥饿：会



> 例题:各进程到达就绪队列的时间、需要的运行时间如下表所示。
>
> 使用多级反馈队列调度算法，分析进程运行的过程。
> ![img](D:\Typora\Images\6bb891bf31664a1e9d70c05e75bdfc69.png)
>
>  ![img](D:\Typora\Images\95a0b4cc6b1245168efc68267a1664cb.png)
>
> 
>
> P1(1)->P2(1)->P1(2)->P2(1)->P3(1)->P2(2)->P1(4)
>
> 时间0：P1进入第一队列，运行1，后进入第二队列队尾
>
> 时间1：P2到达第一队列，运行1，后进入第二队列队尾
>
> 时间2：P1运行2，后进入第三队列队尾
>
> 时间4：P2运行1s后，P3进入第一队列**，P2被抢占**，进入第二队列队尾
>
> 时间5：P3进入第一队列，P3运行1
>
> 时间6：P2运行2
>
> 时间8：P1运行4



## 进程同步

### 引入原因

协调进程之间的相互制约关系

### 制约关系

- **同步**：亦称**直接制约关系**，是指**为完成某种任务而建立的两个或多个进程**，这些进程因为需要在某些位置上协调他们的**工作次序而等待**、传递信息所产生的制约关系
- **互斥**：也称**间接制约关系**，当一个进程进入**临界区使用临界资源**时，另一个进程必须**等待**，当占用临界资源的进程**退出**临界区后，另一个进程才运行去访问此临界资源

### 临界资源

一次仅允许一个进程使用的资源**（打印机、共享缓冲区、共享变量、公共队列）**

### 临界区

在每个进程中访问临界资源的**那段程序**

### 临界区互斥

原则

- **空闲让进**：如果有若干进程要求进入空闲的临界区，**一次仅允许一个进程进入**
- **忙则等待**：任何时候，**处于临界区内的进程不可多于一个**。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待
- **有限等待**：进入临界区的**进程要在有限的时间内退出**，以便其它进程能及时进入自己的临界区
- **让权等待**：如果进程不能进入自己的临界区，则应该**让出CPU**，避免进程出现“忙等”的现象

基本方法

- 信号量：**利用PV操作实现互斥**

## 信号量(信号量机制是一种有效实现进程同步和互斥的工具)

信号量的物理意义∶

(1)信号量的值大于0︰表示当前资源可用数量【S=5    有5个可用资源】

小于0:其绝对值表示等待使用该资源的进程个数【S=-5    有5个进程在等待S资源】

(2)信号量初值为非负的整数变量，代表资源数。

(3)信号量值可变，但仅能由P、V操作来改变。

## P/V操作原语

### 1）P操作原语P(S)

(1)P操作一次，S值减1，即S=s-1(请求分配一资源）【P(s)=S-1    消耗一个资源】【S=5    P（s）；     S=4】

(2)如果S≥0，则该进程继续执行;

如果S<0表示无资源则该进程的状态置为阻塞态，【相当于阻塞队列】

把相应的PCB连入该信号量队列的末尾,并放弃处理机，进行等待(直至另一个进程执行V (S）操作)



### 2)V操作原语(荷兰语的等待)V(S)

(1)v操作一次，s值加1，即S=S+1(释放一单位量资源)

(2)如果S>0，表示有资源，则该进程继续执行;如果S≤0，则释放信号量队列上的第一个PCB所对应的进程(阻塞态改为就绪态)，执行v操作的进程继续执行。



### 2)用P、V原语操作实现简单同步的例子

S1缓冲区是否空(0表示不空，1表示空)，初值S1=0;

S2缓冲区是否满(0表示不满，1表示满)，初值S2=0;



### 3)生产者——消费者问题(Os典型例子):找到同步和互斥的关系

mutex互斥信号量，初值为1;

full满缓冲区数，初值为0;

empty空缓冲区数，初值为N;


一组生产者和一组消费者共享一个初始为空，大小为n的缓冲区，【生产者生产->消费者取 同步关系】

只有当缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待，

只有当缓冲区不空时，消费者才能从中取出消息，否则必须等待，

只允许一个生产者放入消息，或者一个消费者取出消息。【生产者的放 和 消费者的取 互斥关系】

```cpp
伪代码

Semaphore mutex=1;//临界区信号量（互斥）        

【信号量Semaphore，实现互斥的时候mutex=1，当一个进程使用资源的时候P（mutex），mutex=0，则资源数为0，其它进程无法使用资源】

Semaphore empty=n;//空闲缓冲区为n个

Semaphore full=0;//满缓冲区数(有资源)【full=0代表没有缓冲区被充满】

producer(){
    
    while(1){
        
    produce an item in nextp;//生产一个东西

    P(empty);    //空缓冲区-1

    P(mutex);    //互斥的访问缓冲区，mutex=0，生产者进入了缓冲区

【这里两个P操作不能交换：若交换，则生产者占用缓冲区mutex=0，若此时缓冲区全满empty=0，则发生阻塞，生产者等待消费者消费，但消费者无法进入临界区，则死锁】

    add nextp to buff;    //行为

    V(mutex);    //离开缓冲区

    V(full);    //提供了资源

    }

}

consumer(){
    
    while(1){

    P(full);    //看看缓冲区是不是有资源的，有则-1

    P(mutex);    //进入临界区

【不能对调，对调死锁】

    remove an item from buffer;

    V(mutex);    //释放临界区

    V(empty);    //空缓冲区+1

    }    

}
```

## 死锁

### 产生的原因

**非剥夺资源的竞争**和进程的**不恰当推进顺序**（与饥饿的区别：饥饿为缺乏某些资源的进程）

### 1)系统资源的竞争

通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。

只有对**不可剥夺资源的竞争才可能产生死锁**，对**可剥夺资源的竞争是不会引起死锁的**。

【P1有资源A，需要资源B，且不会释放资源A；     P2有资源B，需要资源A，且不会释放资源B；    死锁】

【P1需要A资源4个    P2需要A资源4个    A资源只有6个，且A资源为不可剥夺资源    P1申请了3个，P2申请了3个，P1P2都在申请，但没有了】



### 2)进程推进顺序非法

进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。

例如,并发进程P1、P2分别保持了资源R1、R2，而进程P1申请资源R2，进程P2申请资源R1时，两者都会因为所需资源被占用而阻塞。

【P1申请R1，R2，后结束释放资源，P2再申请R1、R2，则无阻塞】

### 3)死锁产生的**必要条件：死锁产生一定是因为4个条件，但4个条件不一定产生死锁**

**互斥条件**:进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。(**这个是一定要有的，不管会不会产生死锁，这个条件都必须存在**)

**不剥夺条件**:进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放(只能是主动释放）

**请求和保持条件**︰进程已经保持了至少一个资源，但又提出了新的资源请求,而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

**循环等待条件**:存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。

【P1->P2->P3->P4->P1：P1等P2的资源，2等3，3等4，4等1】

当死锁产生的时候一定会有这四个条件，有一个条件不成立都不会造成死锁。其中互斥使用资源是无法破坏的



### 定义

多个进程因**竞争资源**而造成的一种**僵局**，如果**没有外力，这些进程将无法推进**

## 解决方法

解决死锁的三种方法:死锁的预防、避免、检测与恢复。

### 1.死锁预防的基本思想和可行的解决办法

1.**死锁预防**的基本思想:打破产生死锁的四个必要条件的一个或几个。【主动出击】

2**.避免死锁**的策略︰在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。【躲着它】

3.**死锁的检测及解除**【一开始不作为，然后一步到位：不预防避免死锁，有死锁再解除】

无需采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。



## 预防死锁

- 破坏**互斥**条件
- 破坏**不剥夺**条件
- 破坏**请求和保持**条件
- 破坏**循环等待**条件

### 1)破坏互斥条件(不行)

如果允许系统资源都能共享使用，则系统不会进入死锁状态。

但**有些资源根本不能同时访问**，如打印机等临界资源只能互斥使用。

所以，破坏互斥条件而预防死锁的方法**不太可行**，而且在有的场合应该保护这种互斥性。



### 2)破坏不剥夺条件

当一个已保持了某些不可剥夺资源的进程，请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。

这意味着，**一个进程已占有的资源会被暂时释放，或者说是被剥夺了，或从而破坏了不可剥夺条件。**

【P1有3个A资源，请求3个B资源，B资源没有，则释放3个A资源】



### 3)破坏请求和保持条件

#### 第一种协议

**采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。**

**一旦投入运行后，这些资源就一直归它所有，也不再提出其他资源请求，这样就可以保证系统不会发生死锁。**

【P1 需要A3 B4 C5    ，现在P1有A2 B3 C0    ，申请A1 申请B1 申请C5，全部申请完就允许】

这种方式实现简单，但缺点也显而易见，**系统资源被严重浪费**，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。

而且还会导致**“饥饿”**现象，当由于**个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。**

【P1过程    T1只需要A资源    T2 需要B    T3需要C    后结束，但在T1时刻有ABC资源，造成浪费】

#### 第二种协议

对第一种协议的改进，**允许一个进程只获得运行初期所需要的资源后，便开始运行。在运行过程中逐步释放自己的，且已经用毕的全部资源，然后再请求新的所需资源。**

**可以使进程更快的完成任务，提高设备的利用率，还可以减少进程发生饥饿的概率。**

### 4)破坏循环等待条件

为了破坏循环等待条件，可采用**顺序资源分配法**。首先给系统中的资源编号规定每个进程，**规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。**

也就是说，只要进程提出申请分配资源Ri，就必须把Ri以下的编号全部申请到才能运行(导致资源的浪费)，则该进程在以后的资源申请中，**只能申请编号大于Ri的资源。**

## 避免死锁

- **安全状态**
- **银行家算法**

银行家算法是最著名的**死锁避免算法**。

它提出的思想是:把操作系统看做是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。

操作系统按照银行家制定的规则为进程分配资源，

当进程**首次申请**资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。

【max>available，申请量大于可申请，则推迟】

当进程在**执行中**继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量

【max>available，申请量之和大于可申请，则推迟】

若超过则拒绝分配资源，

若没有超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，

若能满足则按当前的申请量分配资源，

否则也要推迟分配。



### 1)数据结构描述

**可利用资源矢量Available**:含有m个元素的歉组，其中的每一个元素代表一类可用的资源数目。Available[j]=K，则表示系统中现有Rj类资源K

**最大需求矩阵Max**:为n*m矩阵，定义了系统中n个进程中的每一个进程对m类资源的最大需求。Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。

**分配矩阵Allocation**:为n*m矩阵，定义了系统中每一类资源当前已分配给每一进程的资源数。AlloCation[i,j]=K，则表示进程i当前已分得Rj类资源的数目为K。

**需求矩阵Need**:为n*m矩阵，表示每个进程尚需的各类资源数Need[i,j]=K，则表示进程i还需要Rj类资源的数目为K。

Need[i,j]=Max[i,j]-Allocation[i,j]



### 2)银行家算法描述

设Requesti是进程Pi的请求矢量，如果Requesti[j]K，表示进程Pi需要Rj类资源K个。当Pi发出资源请求后，系统按下述步骤进行检查:

①如果Requesti[j]<=Need[i,j]，便转向步骤②;否则认为出错

因为它所需要的资源数已超过它所宣布的最大值。

②如果Requesti[ij]<=Available[i]，便转向步骤③;否则，表示尚无足够资源，Pi须等待。

③系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值:

1.Available[j]=Available[i]- Requesti[j];

2.Allocation[i,j]= Allocation[i,j]+ Requesti[ j];

3.Need[i,j] = Need[i,j] - Requesti[j];

④系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。

若安全，才正式将资源分配给进程Pi，以完成本次分配;否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。



## 检测死锁：利用**死锁定理**

## 解除死锁

- 资源剥夺法
- 撤销进程法
- 进程回退法

## 进程管理习题讲解

## 题1

一个四道作业的操作系统中，设在一段时间内先后到达6个作业，它们的提交时间和运行时间见表

![img](D:\Typora\Images\324010f1e7a9462a95e226f2cd47ae16.png)

系统采用**短作业优先**的调度算法，作业**被调度进运行后不再退出【非抢占式】**，但当一作业进入运行时，可以调整运行的优先次序。

1按照所选择的调度算法，请分别给出上述6个作业的执行时间次序

> 次序156342
>
> JOB1提交到完成为9:00，JOB2-6已经全部提交，**短作业优先：**则选择时间短到长的进行排序56342

> 标准答案
>
> 标准的运行流程如下
>
> ![img](D:\Typora\Images\4da77eb25b0b4f6ab1192fa3800a1b82.png)



2计算在上述调度算法下作业的平均周转时间

> **周转时间T=作业完成时间-作业的提交时间**
>
> 平均周转时间=1/n(T1+T2+....Tn)    
>
> n为作业进程数，本题为6

> 标准答案
>
> T1=60
>
> T2=135
>
> ...
>
> T6=35
>
> 平均周转时间=1/6*（60+135+70+90+30+35）=70



## 题2

一个具有两道作业的批处理系统【进程只允许在内存中存在两个】，

作业调度【从外存向内存里面调度】采用短作业优先的调度算法，

进程调度【分配处理机cpu】采用以**优先数**为基础的**抢占式**调度算法，如下表的作业序列

(表中所有作业优先数即为进程优先数，**数值越小优先级越高**)。

![img](D:\Typora\Images\972e605cf0be4e7fb4339f24e5b686ed.png)

1.列出所有作业进入内存时间及结束时间

> 作业ABCD都在外存，可以向内存中调入两个作业，按优先数进入CPU
>
> 到达时间
>
> 10:00    A到达 进入内存    CPU运行
>
> 10:20    B到达 进入内存    内存中有AB A运行20min，剩余20min    B优先数高，B开始运行
>
> 10:30    C到达，A剩余20min，B运行10min，剩余20min    由于采用短作业优先算法，50>20=20，所以C不被调入内存
>
> 10:50    D到达，B作业完，下处理机，下内存    由于采用短作业优先算法，C50min，D20min，D进入内存    内存有AD，进程调度A优先数高，A进CPU
>
> 11:10    A结束    C进内存，内存有CD，C优先数高，先进处理器
>
> 12:00    C结束，D进处理器
>
> 12:20    D结束

> 标准答案
>
> 1、10:00，A作业到达，进入系统开始运行。
>
> 2、10∶20，B作业到达，系统内存中只有一道作业A，B作业进入内存，此时A运行20min，还剩20min,由于B作业的优先数小，即优先级高，则作业A进入就绪状态，作业B开始运行。
>
> 3、10∶30，C作业到达，内存中已有两道作业，则在后备队列中等待被作业调度程序调度，A等待10min,剩20min,继续等待，B运行10min,还剩20min,继续运行。
>
> 4、10∶50，D作业到达，B作业完成，内存中只剩下作业A,剩20min，作业D与作业C相比，作业D的运行所需时间少被调到进内存，内存中的A和D相比，A的优先级高，A继续运行。
>
> 5、11∶10，作业A运行完成，作业C被调度进内存，内存中有作业D和作业C，C的优先级比D高，C先运行。
>
> 6、12: 00，作业C完成，D运行。
>
> 7、12∶20，作业D完成
>
> ![img](D:\Typora\Images\a3d9efdb2aa44792a91c4d42abb08280.png)

2.计算平均周转时间

>  各作业执行时间的周转时间为
>
> 作业A 70分钟
>
> 作业B30分钟
>
> 作业C 90分钟
>
> 作业D 90分钟
>
> 作业的平均周转时间为T=70 (min)



## 题3.有5个批处理作业(A、B、C、D、E)几乎同时到达一个计算中心，估计的运行时间分别为2，4，6，8，10分钟，

它们的优先数分别为1，2，3，4，5(1为最低优先级)，

对下面的每种调度算法，分别计算作业的平均周转时间。

1最高优先级先

2时间片轮转(时间片为2分钟)

3 FIFO( FCFS ) (作业到达顺序为C、D、B、E、A)

4短作业优先

【题目没提：默认为非剥夺式】

> 1对最高优先级优先算法
>
> ![img](D:\Typora\Images\7d35a260e9e44dea8ca9efb4f552dd8d.png)
>
> 平均周转时间=（10+18+24+28+30）/5=22分钟

> 2对时间片轮转算法
>
> ![img](D:\Typora\Images\c7d2881974534efdaa63569c798fd343.png)
>
> 平均周转时间=(2+12+20+26+30)/5=18

> 3 FIFO (作业到达顺序为C、D、B、E、A)
>
> ![img](D:\Typora\Images\20d93ef89fd742029e7e43c9dcd4c2df.png)
>
> 平均周转时间=(6+14+18+28+30)/5=19.2

> 4短作业优先
>
> A:2 B:4 C:6 D:8 E:10
>
> 平均周转时间=(2+6+12+20+30)/5=14



## 题9.银行家算法中，若出现下述的资源分配情况:



![img](D:\Typora\Images\86e1d61919d543669ef3455d7bfd0ed8.png)

【已分配Allocation    尚需need    未分配available    Max=已分配+尚需=Allocation+Need    后available=原available+Allocation】

⑴该状态是安全的吗?【假设P0->P1->P2->P3->P4可以执行结束，我能够找到一个安全序列，则该状态是安全的】

> 未分配2431，可以给P0用，P1不行，P2不行，P3不行，P4不行，所以先运行P0，运行结束未分配为2441
>
> 未分配2441，P1不行，P2不行，P3行，P4不行，运行P3，结束未分配为2572
>
> 未分配2572，P1不行，P2不行，P4行，运行P4，结束未分配为2586
>
> 未分配2586，P1不行，P2行，运行P2，结束未分配为3 8 13 10
>
> 未分配3 8 13 10，P1行，运行P1
>
> 所以安全序列为P0->P3->P4->P2->P1

> 标准答案
>
> P0(2 4 4 1)->P3(2572)->P4(2 5 8 6)->P2(3 8 13 10)->P1(4 8 13 10)为其中一个安全序列，所以该状态安全。

⑵如果P1再提出资源请求Request (0 3 2 1)，系统能否将资源分配给它?【找不到安全序列，系统处于危险状态，不能分配】

> 标准答案
>
> 因为一旦分配，P1还需P1(0 4 3 0),系统的可用资源数为(2 1 1 1)，
>
> 在所有进程中只有P0(2 0 1 0)，为其分配，作上完成标志，可用资源为(2 1 2 1);
>
> 而P1/P2/P3/P4均不能作上完成标志

# 第四章 内存管理

## 引入目的

更好的支持多道程序的**并发执行**，提高系统性能

## 主要功能

### 内存空间的分配与回收

### 存储的保护和共享：

保证各道作业在各自的存储空间内运行，互不干扰。

### 地址转换：

在多道程序环境下，程序中的**逻辑地址**与内存中的**物理地址**不可能一致，因此存储管理必须提供地址变换功能，把**逻辑地址转换成相应的物理地址**

### 内存扩充：

利用**虚拟存储技术或自动覆盖技术**，从**逻辑上**扩充内存。



## 用户程序的主要处理阶段

### 1). 编辑阶段

创建源文件

### 2). 编译阶段

由编译程序将用户源代码编译成若干**目标模块**，生成目标文件

### 3). 链接阶段

由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起， 形成一个完整的装入模块。生成**可执行文件（\**形成逻辑地址\**）**

### 4). 装入阶段

由装入程序将装入模块**装入内存**运行。

### 5). 运行阶段

得到结果

## 相关概念

### 程序的装入

- 绝对装入（逻辑地址必须和实际的内存地址完全一样)
- 静态重定位（地址变换在装入时一次完成）：***\*装入内存的时候地址变换\****
- 动态重定位（地址变换在执行程序的时候再完成）：***\*运行的时候地址变换\****

### 程序的链接

- 静态链接
- 装入时链接
- 运行时链接

### 地址空间

- 逻辑地址空间（地址空间从0开始）
- 物理地址空间（内存中物理单元的集合）

## 管理方式

## 连续分配管理方式：物理地址连续，逻辑地址连续

### 1.单一连续分配

分配到内存固定的区域（有内部碎片）：***\*分配给进程的内存有一部分没有用上\****

> 例如：30mb分30mb

### 2.固定分区分配

分配到内存不同的固定区域，分区可以相等可以不等（内部碎片）

> 例如：30mb分为10mb和20mb

### 3.动态分区分配

#### 可变分区存储管理：

按照**程序的需要**进行**动态的划分**

#### 动态分区的分配策略算法

#### 首次适应（***\*最好\****）

空闲分区以**地址递增的次序**链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。（**增加查找开销**）

> 例如：从0x0001到0xFFFF顺序查找，30mb小了，20mb小了，40mb合适就你了

#### 最佳适应

空闲分区按容量递增的方式形成分区链，找到第一个能满足要求的空闲分区。（**外部碎片过多**）

> 例如：从1mb到9999mb查找，1mb小了，2mb小了，3mb合适
>
> **外部碎片:因为碎片过小而无法利用，例如30mb的**空闲分区，进程需要29.999mb，剩下的0.001mb为外部碎片

#### 最坏适应

空闲分区以**容量递减**的次序链接。找到第一个能满足要求的空闲分区，即挑选出最大的分区。（**对大进程不利**）

> 例如：空闲分区有100mb，70mb，........，1mb
>
> 70mb进程来了进100mb的空闲分区，然后100mb进程来了就要等等等

#### 邻近适应

由首次适应算法演变而成。不同之处是，**分配内存时从上次查找结束的位置开始继续查找**。

> 例如：第一次找到了0xFF00，第二次从0xFF00开始找

#### 非连续分配管理方式（大题）：物理地址不连续，逻辑地址连续

基本分页式存储管理

基本分段式存储管理

段页式

## 内存扩充

### 1覆盖（同一程序或进程中）

### 2交换（不同进程/作业之间进行）

> 在打大型游戏时候，将QQ微信放到外存

## 虚拟内存

### 引入原因

在逻辑上扩充内存

### 组成部分

- 页表机制
- 中断机制
- 地址变换机制
- 内存与外存

### 页面淘汰（置换）算法：

注意：页面淘汰是由缺页中断引起的，但缺页中断不见得一定引起页面淘汰

### 先进先出页面淘汰（置换）算法（FIFO）

淘汰最先进入内存的页面（3个内存块都为空，3次缺页中断）

注：对于FIFO页面淘汰算法，有时增加分配给作业的可用内存块数，它的缺页次数反而上升，通常称为异常现象

### 最近最久未用页面淘汰（置换）算法（LRU）

总是把最长时间未被访问过的页面淘汰出去（需要寄存器和栈）

### 最近最少用页面淘汰（置换）算法（clock）

总是把当前使用的最少的页面淘汰出去

### 最优（最佳）页面淘汰（置换）算法（OPT）

把以后不再使用的或最长时间内不会用到的页面淘汰出去（理论上，不会实现）

### 抖动

页面频繁的换进换出

原因：分配给进程的进程块不足

### 页面分配的策略

固定分区局部置换（物理块不变)

> 给进程分配3个物理块，不变

可变分配局部置换  (动态增加物理块)

> 给进程分配3个物理块，缺页，加一块

可变分配全局置换(只允许从该进程的内存页面中挑选一页)



# 例题

### 一个请求页式存储系统中，

### 一个程序的页面走向为2，3，1，2，4，3，5 , 7，2，3，4，3，6，2，1，3，4，1

### 假设分配给程序的存储块数为3块【三个物理块中有三个页，第四个来了，要挑一个页出来换】，

### 请给出OPT、FIFO、LRU每种页面置换算法的页面走向，并计算缺页率。

解:OPT最佳置换算法︰淘汰最远将来才使用的页。

> 2，3，1，2，**4【引起缺页，要换123之中的一个】**，3【3最近要使用】，5 , 7，2【2最近要使用】，3，4，3，6，2，1【1最远使用，所以淘汰1】，3，4，1

FIFO先进先出置换算法:淘汰最先进来的页。

> 2【最先进来，最先淘汰2】，3，1，2，**4【引起缺页，要换123之中的一个】**，3，5 , 7，2，3，4，3，6，2，1，3，4，1

LRU最近最久未使用置换算法:最近最久未使用的页。

> 2，3【因为2更新，所以3为最久未使用，所以淘汰3】，1，2【2更新】，**4【引起缺页，要换123之中的一个】**，3，5 , 7，2，3，4，3，6，2，1，3，4，1

![img](D:\Typora\Images\7881d7e08f6c4d938064384af036aa74.png)







# 第五章 文件系统

# 文件、文件系统

### 概念

文件是以计算机**硬盘**为载体的存储在计算机上的信息集合

文件系统：就是操作系统中负责操纵和管理文件的一整套设施，它实现文件的共享和保护，方便用户**按名存取（\**基本目标\**），提高文件的存取速度（\**最重要目标\**）**。

### 功能

文件管理、目录管理、文件空间管理、文件共享和保护、提供方便的接口。

# 文件的逻辑结构

### 无结构文件（即流式文件）

> 例如文本框中打字

### 有结构文件（记录式文件）

- 顺序文件

> 磁带上的文件一定是顺序文件

- 索引文件
- 索引顺序文件

# 目录和目录结构

### 文件控制块FCB

在文件系统内部给每个文件**惟一**地设置一个文件控制块，它用于描述和控制文件的数据结构，与文件一一对应

> 类似进程的PCB

### 目录结构

- 单级目录（不允许重名）
- 二级目录（解决了重名问题）：主文件目录MFD和用户文件目录UFD
- 树形目录（优点：方便，缺点：不方便共享）：绝对路径（从根目录出发）和相对路径（从当前目录出发）
- 图形目录（实现了共享）

# 文件实现

### 文件分配方式

- 连续分配（有外部碎片）
- 链接分配（解决了外部碎片，但是不支持直接访问，数据易丢失）
- 索引分配（加入FAT表可直接访问，减少了访问磁盘的次数）

### 文件存储空间管理（大题）

1）空闲表法

**2）空闲链表法**

**3）位示图法**

# 磁盘管理

### 磁盘地址结构

柱面号、盘面号、扇面号

### 磁盘调度算法（必考大题）

先到先服务算法（FCFS）

最短查找时间优先算法（SSTF）

扫描算法和LOOK算法（SCAN）：类似电梯

循环扫描算法和循环LOOK算法：单项循环电梯

## 例题

题11.假设系统中磁头当前的位置在110号磁道上，

设有若干个进程先后提出磁盘I/O请求序列为65，68，49，28，100，170，160，48和194。

(1)按FCFS算法进行调度的平均寻道距离;

解:(1)平均寻道距离55.3条磁道

110->65->68->49->28->100->170->160->48->194

![img](D:\Typora\Images\cc5d556c623b48a8b29097ab0534d18d.png)![img](D:\Typora\Images\f085df7efafb463bae34c7b04f209a1b.png)

 (2)按SSTF算法进行调度的平均寻道距离;

 110->100->68->65->49->48->28->160->170->194

 (3)按SCAN算法进行调度的平均寻道距离;【题目没给最外侧磁道数目，则扫描到题目给出的最大数目194，若给了例如200，则要扫描到200】

110->160->170->194->100->68->65->49->48->28

 (4)按循环SCAN算法进行调度的平均寻道距离;    

110->160->170->194->28->48->49->65->68->100



# 第五章 设备管理

# 设备管理的目标

使用方便、与设备无关、效率高、管理统一。

# I/O设备

### 分类

- 存储设备或输入输出设备
- 块设备或字符设备
- 低速中速高速设备

## I/O控制方式

### ①程序直接控制方式

这种方式也可以称为查询方式，cpu不断地去查询设备控制器是否将数据放到了数据存储器中，或者从数据存储器存到设备中，当完成IO时cpu才能去干别的事。

### ②中断方式：

这种方式当cpu发出指令后就可以去干别的事，当设备控制器把数据存在数据存储器后，向cpu发出中断请求，然后cpu再来处理这部分数据。

### ③DMA方式：

虽然中断方式提高了cpu的利用率，但是数据寄存器有限，**中断是以字节单位进行中断**，也就是说读取或存储一个字节后就需要进行中断，那么其实cpu的利用率还是很低的，所以就诞生了DMA方式，这种方式由DMA控制器直接将设备中的数据以**数据块**为单位直接传输到内存中，当传输结束后才向cpu发起中断。

### ④IO通道控制方式：

DMA虽然大大地提升了cpu的利用率，但是DMA只能传输一个连续的数据块。所以引入了IO通道的控制方式，**IO通道控制方式可以传输不连续的数据块**，减少了cpu干预。cpu通过对IO通道发出指令，然后让IO通道自己工作，等数据传输完才向cpu发起中断。

# 引入缓冲的目的和缓冲区的设置方式

## 1. 引入缓冲区的目的

\1) 缓和CPU与外设间**速度不匹配**的矛盾

\2) 提高CPU与外设之间的**并行**性

\3) **减少**对CPU的**中断次数**

## 2. 缓冲区的设置方式

\1) 单缓冲：当数据到达率与离去率相差很大时，可采用单缓冲方式。

\2) 双缓冲：当信息输入和输出率相同（或相差 不大）时，可利用双缓冲区，实现两者的并行。【非空不能放东西，非满不能取东西】

\3) 多缓冲：对于阵发性的输入、输出，为了解决速度不匹配问题，可以设立多个缓冲区。

> 循环缓冲区：分为三个队列：空缓冲队列，输入队列：装满输入数据的缓冲队列，输出队列：装满输出数据的缓冲队列
>
> 四个缓冲区：收容输入数据的工作缓冲区，提取输入数据的工作缓冲区，收容输出数据的工作缓冲区，提取输出数据的工作缓冲区

# 常用设备分配技术

## 1. 根据设备的使用性质

\1) 独占设备：

不能共享的设备，即：在一段时间内，该设备只允许一个进程独占。如打印机。

\2) 共享设备：

可由若干个进程同时共享的设备。如磁盘机。

\3) 虚拟设备：

是利用某种技术把独占设备改造成可由多个进程共享的设备。



### 2. 针对三种设备采用三种分配技术

\1) 独占分配技术：

是把独占设备固定地分配给一个进程，直至该进程完成I/O操作并释放它为止。

\2) 共享分配技术：

通常适用于高速、大容量的直接存取存储设备。由多个进程共享一台设备，每个进程只用其中的一部分。

\3) 虚拟分配技术：

利用共享设备去模拟独占设备，从而使独占设备成为可共享的、快速I/O的设备。实现虚拟分配的最有名的技术是SPOOLing技术，也称作假脱机操作。

【分配技术应该考虑：固有性质、分配算法、安全性、独立性【应用程序独立于具体使用的物理设备】】